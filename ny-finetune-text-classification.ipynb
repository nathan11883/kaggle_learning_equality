{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate\n!pip install tqdm","metadata":{"_uuid":"90c74aaa-7a81-4a29-9411-c29bcc18ed24","_cell_guid":"8463d0b3-d413-4abe-be93-238d0826e901","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:43:58.788203Z","iopub.execute_input":"2023-02-23T18:43:58.788945Z","iopub.status.idle":"2023-02-23T18:44:18.991661Z","shell.execute_reply.started":"2023-02-23T18:43:58.788907Z","shell.execute_reply":"2023-02-23T18:44:18.990405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cloud Storage\n# from google.cloud import storage\n# storage_client = storage.Client(project='YOUR PROJECT ID')","metadata":{"_uuid":"70a8e677-b501-4de7-8637-181a6b7de4b5","_cell_guid":"664f24d6-03a8-4304-bdc7-13bd77f626f8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:18.994249Z","iopub.execute_input":"2023-02-23T18:44:18.994775Z","iopub.status.idle":"2023-02-23T18:44:19.002633Z","shell.execute_reply.started":"2023-02-23T18:44:18.994731Z","shell.execute_reply":"2023-02-23T18:44:19.001673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport math\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nfrom datasets import Dataset, load_dataset, load_from_disk\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer\nimport torch \nfrom pynvml import *\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"3a0c8146-f608-4765-9e84-be2c4bc1f2c5","_cell_guid":"eb6334c5-ca12-4b42-9d37-0b52413f9638","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:19.004194Z","iopub.execute_input":"2023-02-23T18:44:19.004568Z","iopub.status.idle":"2023-02-23T18:44:21.489309Z","shell.execute_reply.started":"2023-02-23T18:44:19.004533Z","shell.execute_reply":"2023-02-23T18:44:21.488280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n\n\ndef print_summary(result):\n    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n    print_gpu_utilization()\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"a274d3ef-c926-4add-b051-29d66f121278","_cell_guid":"abf35b85-a84f-4950-ba35-a66f4b3ffb93","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:21.491988Z","iopub.execute_input":"2023-02-23T18:44:21.492750Z","iopub.status.idle":"2023-02-23T18:44:21.513932Z","shell.execute_reply.started":"2023-02-23T18:44:21.492709Z","shell.execute_reply":"2023-02-23T18:44:21.512844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Refresh_Topic = False\nRefresh_Train_Data = False\nRefresh_Tokenize_DB = False\nTrain_model = False\ndver = 201","metadata":{"_uuid":"14d2f2c9-9654-4858-9b71-cc48a04f002e","_cell_guid":"9baf4c94-d9d6-4e57-b4db-d0b09f5a2218","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:21.515552Z","iopub.execute_input":"2023-02-23T18:44:21.515940Z","iopub.status.idle":"2023-02-23T18:44:21.521138Z","shell.execute_reply.started":"2023-02-23T18:44:21.515904Z","shell.execute_reply":"2023-02-23T18:44:21.519806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/learning-equality-curriculum-recommendations/\"\ntopics = pd.read_csv(DATA_PATH + \"topics.csv\")\ncontent = pd.read_csv(DATA_PATH + \"content.csv\")\ncorrelations = pd.read_csv(DATA_PATH + \"correlations.csv\")\ndf_topics = None","metadata":{"_uuid":"8251ab12-db12-458b-a5e8-88ba3c6adb94","_cell_guid":"cc4e344d-9fc7-4f1e-9550-0e4eacdc36ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:21.523371Z","iopub.execute_input":"2023-02-23T18:44:21.523929Z","iopub.status.idle":"2023-02-23T18:44:44.851315Z","shell.execute_reply.started":"2023-02-23T18:44:21.523887Z","shell.execute_reply":"2023-02-23T18:44:44.850309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_topic_file = f\"./data/df_topics_v{dver}.pkl\"\ntrain_data_file= f\"./data/df_train_v{dver}.pkl\"\nfull_tokenized_db_file=f\"./data/full_tokenized_db_v{dver}.hf\"\nmodel_name = f\"lecr-text-classification-v{dver}\"\nmodel_file = f\"./model/kaggle/working/{model_name}\"\ntrained_model_file = f\"./model/kaggle/working/{model_name}_{dver}\"","metadata":{"_uuid":"c8be412b-8e5f-4036-8f45-cfde0b046ef4","_cell_guid":"39a7cca4-73c9-4463-a95a-0501dc055b7f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:44.852791Z","iopub.execute_input":"2023-02-23T18:44:44.853155Z","iopub.status.idle":"2023-02-23T18:44:44.861092Z","shell.execute_reply.started":"2023-02-23T18:44:44.853120Z","shell.execute_reply":"2023-02-23T18:44:44.860103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ( not topics.columns[0].startswith(\"topic_\")):\n    topics.rename(columns=lambda x: \"topic_\" + x, inplace=True)\n    content.rename(columns=lambda x: \"content_\" + x, inplace=True)","metadata":{"_uuid":"8cff26f9-1328-4f01-8929-149b78da230b","_cell_guid":"4309b2e2-3736-4b67-97aa-95998e823da4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:44.862245Z","iopub.execute_input":"2023-02-23T18:44:44.863458Z","iopub.status.idle":"2023-02-23T18:44:44.872092Z","shell.execute_reply.started":"2023-02-23T18:44:44.863417Z","shell.execute_reply":"2023-02-23T18:44:44.871125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_parents(df, row):\n    topic_id = row[\"topic_id\"]\n    topic_title = str(row[\"topic_title\"])\n    topic_description = str(row[\"topic_description\"])\n    topic_parent = row[\"topic_parent\"]\n    topic_level = row[\"topic_level\"]\n#     while topic_level > 0:\n# assume we only have one parent\n    subset = df.loc[df['topic_id'] == topic_parent]\n    if(len(subset) > 1):\n        print(f\"We found multiple parents for topic: {topic_id} parent_id: {topic_parent}\")\n    for index, r in subset.iterrows():\n        if (not pd.isna(r[\"topic_title\"])):\n#             print(r[\"topic_title\"])\n            topic_title = str(r[\"topic_title\"]) + \".\" + topic_title\n        topic_parent = r[\"topic_parent\"]\n        topic_level = r[\"topic_level\"]\n        break\n#     print(topic_title)\n    return topic_title","metadata":{"_uuid":"0d2575f7-96e5-4c15-8b21-f124eaeaca94","_cell_guid":"a380b091-8552-4235-b7e1-8a3f34f2aefd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:44.873376Z","iopub.execute_input":"2023-02-23T18:44:44.873816Z","iopub.status.idle":"2023-02-23T18:44:44.882975Z","shell.execute_reply.started":"2023-02-23T18:44:44.873780Z","shell.execute_reply":"2023-02-23T18:44:44.881850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def refresh_topic(topics):\n\n    df_topics = topics\n\n    print(df_topics.head())\n\n    title_full = []\n\n\n    for index, row in tqdm(df_topics.iterrows(), total=df_topics.shape[0]):\n\n        topic_title = get_parents(df_topics, row)\n        title_full.append(topic_title)\n\n\n    df_topics['topic_title_full'] = title_full\n\n    print(df_topics.head())\n\n    df_topics.to_pickle(processed_topic_file) \n    return df_topics","metadata":{"_uuid":"63dbb94e-cf33-4547-937e-742d3e0a5ee3","_cell_guid":"569b9109-43f0-4997-8a19-d6330a05b603","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:44.889094Z","iopub.execute_input":"2023-02-23T18:44:44.889390Z","iopub.status.idle":"2023-02-23T18:44:44.895540Z","shell.execute_reply.started":"2023-02-23T18:44:44.889336Z","shell.execute_reply":"2023-02-23T18:44:44.894589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (Refresh_Topic):\n    print(f\"Refresh_Topic >>> \")\n    df_topics = refresh_topic(topics)\nelse:\n    print(f\"load df_topics from processed_topic_file\")\n    df_topics = pd.read_pickle(processed_topic_file)","metadata":{"_uuid":"7e7b1317-7257-4c34-aca1-785f84d0bc45","_cell_guid":"c147f3c2-dd5a-478b-a1e1-4e7018c33fe2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-23T18:44:44.896846Z","iopub.execute_input":"2023-02-23T18:44:44.897660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_topics","metadata":{"_uuid":"63d37fac-9776-44a6-ba6a-c85adfb56032","_cell_guid":"b137c712-648a-45fd-97ea-ddf2d5ef7931","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# mf = processed_topic_file\n# mfz = f'{processed_topic_file}.tar.gz'\n# !tar -czf {mfz} {mf}\n\n# from IPython.display import FileLink\n\n# FileLink(mfz)","metadata":{"_uuid":"bbc3b0ad-e7d1-48b4-98a0-7a95c9b1d94a","_cell_guid":"8d99ab39-f5c8-4406-a251-43bac8b602c9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_train_data(topics):\n    train_df_columns = [\"topic_title\", \"content_title\", \"topic_title_full\", \"topic_id\",\"content_id\", \"content_description\", \"content_text\" ]\n    if ( not \"content_id\" in list(topics.columns.values)):\n        correlations[\"content_id\"] = correlations[\"content_ids\"].str.split(\" \")\n        corr = correlations.explode(\"content_id\").drop(columns=[\"content_ids\"])\n\n        corr = corr.merge(df_topics, how=\"left\", on=\"topic_id\")\n        corr = corr.merge(content, how=\"left\", on=\"content_id\")\n\n    #     corr[\"set\"] = corr[train_df_columns].values.tolist()\n\n    #     print(\"Display correlations ....\")\n    #     print(corr.head())\n\n    train_df = pd.DataFrame(corr[train_df_columns])\n    cols = ['content_title', 'content_description', \"content_text\"]\n    train_df['content_full'] = train_df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n    train_df.rename(columns={\"topic_title_full\": \"text_label\", \"content_full\": \"text\"}, inplace=True)\n\n    final_train_data = pd.DataFrame(train_df[[\"text_label\", \"text\"]])\n    final_train_data[\"label\"]= final_train_data['text_label'].astype('category').cat.codes\n\n    # \n\n    # label_list = final_train_data.label_text.unique().sort()\n\n    # label2id = dict(zip(lst, range(len(label_list))))\n    # id2label = {i:t for i, t in enumerate(label_list)}      \n\n    # print(f\"label2id: {label2id}\")\n\n    # print(f\"id2label: {id2label}\n    final_train_data.head()\n    final_train_data.to_pickle(train_data_file)\n    \n    return final_train_data;","metadata":{"_uuid":"6396ba82-0280-4844-b626-06023b9cef9f","_cell_guid":"e5a289dd-89d8-4fbd-aada-ec4532680d6d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Refresh_Train_Data:\n    print(f\"Refresh_Train_Data ==>>>\")\n    final_train_data = load_train_data(topics)\nelse:\n    print(f\"load final_train_data from {train_data_file}\")\n    final_train_data = pd.read_pickle(train_data_file)","metadata":{"_uuid":"cb52ca94-0a72-4706-81a9-5d572a764657","_cell_guid":"ece90f27-58d8-4643-91b1-2899a48210d6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"5b82c1ca-dd2c-4014-9436-adb249435b52","_cell_guid":"d5d53289-92ff-46d3-9062-26923899ce4e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# # os.chdir(r'/kaggle/working')\n# resf = train_data_file\n# reszipf = f\"{resf}.tar.gz\"\n# !tar -czf {reszipf} {resf}\n\n# from IPython.display import FileLink\n\n# FileLink(reszipf)","metadata":{"_uuid":"22362473-c418-4c0d-9d3f-7044c59670d9","_cell_guid":"80af79d7-687e-4638-827a-f27f14168ae5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"text_label count: {len(final_train_data.text_label.unique())}  label count: {len(final_train_data.label.unique())}\")","metadata":{"_uuid":"1f99c6f9-dc3e-45a2-b9a1-3ebb5ceceeb9","_cell_guid":"df89cd03-9171-45be-8fbd-6a681949ad36","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"b5fbe004-f518-479f-8874-1cc2b565e7f5","_cell_guid":"58c3a262-12bb-4d60-9e01-1e6ae655d39f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets","metadata":{"_uuid":"399bee81-3365-4574-845f-03c0607c6cc2","_cell_guid":"b804939f-ff79-4c38-8e8b-c1ab9b93344b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"71f34c42-96c5-42e2-a36f-27f95ec97226","_cell_guid":"dbe15671-2405-4f23-b783-21e057ae0423","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import DataCollatorWithPadding\nimport evaluate\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"_uuid":"20466f08-d733-46db-a7bc-26dc45449821","_cell_guid":"28fd72e0-d0cc-48cc-81fa-9727a499a81a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"_uuid":"3e5f7592-1008-4de8-b039-141e04cf4837","_cell_guid":"b9f6ddc3-dc02-43e0-aca3-12761721c67c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")","metadata":{"_uuid":"256a6cbe-2255-47de-a7ef-b3cd9f5e2702","_cell_guid":"7859c8e9-cea9-4fcf-8f18-cf1a18525e8f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (Refresh_Tokenize_DB):\n    print(f\"Refresh_Tokenize_DB ===>>\")\n    datasets = Dataset.from_pandas(final_train_data).train_test_split(test_size=0.2)\n    full_tokenized_db = datasets.map(preprocess_function, batched=True)\n    full_tokenized_db = full_tokenized_db.remove_columns([\"text\"])\n    full_tokenized_db = full_tokenized_db.rename_column(\"label\", \"labels\")\n    full_tokenized_db.set_format(\"torch\")\n    full_tokenized_db.save_to_disk(full_tokenized_db_file)\n   \nelse:\n    print(f\"load from disk {full_tokenized_db_file}\")\n    full_tokenized_db = load_from_disk(full_tokenized_db_file)\n    # full_tokenized_db = load_dataset(\"\", data_dir=full_tokenized_db_file, streaming=True)\nprint(final_train_data)\nprint(full_tokenized_db)\n\nfrom transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nlabel2id = dict(zip(final_train_data.text_label, final_train_data.label))\nid2label = dict(zip(final_train_data.label, final_train_data.text_label))\nnum_label = len(id2label)\nprint(f\"label2id length: {len(label2id)}\")\nprint(f\"id2label length: {len(id2label)}\")\n\n# # train_label2id = dict(zip(full_tokenized_db[\"train\"][\"text_label\"], full_tokenized_db[\"train\"][\"labels\"]))\n# train_label2id = {}\n# train_id2label = {}\n# idx = 0\n# for val in full_tokenized_db[\"train\"]:\n#     idx += 1\n\n#     train_label2id[val[\"text_label\"]] = val[\"labels\"]\n#     train_id2label[val[\"labels\"]]=val[\"text_label\"]\n#     if (idx % 1000 == 0):\n#         print(idx, val[\"text_label\"], val[\"labels\"], len(train_label2id), len(train_id2label) )\n# print(len(train_label2id),  len(train_id2label))\n# # train_id2label = dict(zip(full_tokenized_db[\"train\"][\"labels\"], full_tokenized_db[\"train\"][\"text_label\"]))\n\n# test_label2id = {}\n# test_id2label = {}\n# idx = 0\n# for val in full_tokenized_db[\"test\"]:\n#     idx += 1\n#     test_label2id[val[\"text_label\"]] = val[\"labels\"]\n#     test_id2label[val[\"labels\"]]=val[\"text_label\"]\n#     if (idx % 1000 == 0):\n#         print(idx, val[\"text_label\"], val[\"labels\"] , len(test_label2id), len(test_id2label) )\n\n# print(len(test_label2id),  len(test_id2label))\n\n# test_label2id = dict(zip(full_tokenized_db[\"test\"][\"text_label\"], full_tokenized_db[\"test\"][\"labels\"]))\n# test_id2label = dict(zip(full_tokenized_db[\"test\"][\"labels\"], full_tokenized_db[\"test\"][\"text_label\"]))\n# label2id = {**train_label2id, **test_label2id}\n# id2label = {**train_id2label, **test_id2label}\n# num_label = len(id2label)\n# print(f\"label2id length: {len(label2id)} train_label2id {len(train_label2id)}, test_label2id {len(test_label2id)}\")\n# print(f\"id2label length: {len(id2label)} train_id2label {len(train_id2label)}, test_id2label {len(test_id2label)}\")\n\nimport evaluate\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"_uuid":"09dc3fef-46ac-4055-8978-796ec3f9d20c","_cell_guid":"35b9b4e7-e62b-43a3-b8b6-a9acc3e6c022","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_tokenized_db","metadata":{"_uuid":"fe4e76fc-93b9-453a-94bc-2dcdcd754714","_cell_guid":"96d20f5c-ab43-47bd-a5e6-dd7f47e05fd4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntorch.cuda.empty_cache()\nimport numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"_uuid":"77a822c0-afdf-4714-9392-0138687934c8","_cell_guid":"ae80f954-dfc0-4c3b-a434-2d907df20ba3","collapsed":false,"execution":{"iopub.status.busy":"2023-02-23T18:28:16.541846Z","iopub.execute_input":"2023-02-23T18:28:16.542217Z","iopub.status.idle":"2023-02-23T18:28:16.547042Z","shell.execute_reply.started":"2023-02-23T18:28:16.542184Z","shell.execute_reply":"2023-02-23T18:28:16.546014Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n\ndef train_model(full_tokenized_db, tokenizer, id2label, label2id, num_label):\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_label, id2label=id2label, label2id=label2id\n    )\n\n\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2023-02-23T18:28:49.718426Z\",\"iopub.execute_input\":\"2023-02-23T18:28:49.718814Z\",\"iopub.status.idle\":\"2023-02-23T18:28:49.786141Z\",\"shell.execute_reply.started\":\"2023-02-23T18:28:49.718782Z\",\"shell.execute_reply\":\"2023-02-23T18:28:49.785207Z\"}}\n    # tokenized_train_db = full_tokenized_db[\"train\"].shuffle(seed=42).select(range(10000))\n    # tokenized_eval_db = full_tokenized_db[\"test\"].shuffle(seed=42).select(range(10000))\n\n    num_shards = 3\n    for shard_idx in range(num_shards):\n        shard_train = full_tokenized_db[\"train\"].shard(num_shards=num_shards, index=shard_idx, contiguous=True)\n        shard_test = full_tokenized_db[\"test\"].shard(num_shards=num_shards, index=shard_idx, contiguous=True)\n\n\n    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-02-23T18:28:54.307592Z\",\"iopub.execute_input\":\"2023-02-23T18:28:54.307965Z\",\"iopub.status.idle\":\"2023-02-23T18:28:54.338904Z\",\"shell.execute_reply.started\":\"2023-02-23T18:28:54.307934Z\",\"shell.execute_reply\":\"2023-02-23T18:28:54.337343Z\"}}\n\n        training_args = TrainingArguments(\n            output_dir=model_file,\n            learning_rate=2e-5,\n            per_device_train_batch_size=8,\n            per_device_eval_batch_size=8,\n            num_train_epochs=2,\n            weight_decay=0.01,\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            load_best_model_at_end=True,\n            gradient_accumulation_steps=8,\n            # gradient_checkpointing=True,\n            fp16=True,\n            optim=\"adafactor\",\n            push_to_hub=False,\n        )\n\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=shard_train,\n            eval_dataset=shard_test,\n            tokenizer=tokenizer,\n            data_collator=data_collator,\n            compute_metrics=compute_metrics,\n        )\n\n        trainer.train()\n        \n        trained_file = trained_model_file + f\"_{shard_idx}\"\n        print(f\"save model to : {trained_file}\")\n        trainer.save_model(trained_file)\n        print(f\"load model from : {trained_file}\")\n\n        model = AutoModelForSequenceClassification.from_pretrained( trained_file, num_labels=num_label, id2label=id2label, label2id=label2id )\n        tokenizer = AutoTokenizer.from_pretrained(trained_file)\n\n# text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"\n# from transformers import pipeline\n\n# classifier = pipeline(\"sentiment-analysis\", model=model_file)\n# classifier(text)\n\nif (Train_model):\n    train_model(full_tokenized_db, tokenizer, id2label, label2id, num_label)\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\ntokenizer = AutoTokenizer.from_pretrained(model_file + \"/checkpoint-2332\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_file + \"/checkpoint-2332\")\n\ntest_datasets = Dataset.from_pandas(final_train_data).train_test_split(test_size=0.2)\n\ndef get_predict_label(text):\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        logits = model(**inputs).logits\n\n    predicted_class_id = logits.argmax().item()\n    # print(model.config.id2label[predicted_class_id])\n    return model.config.id2label[predicted_class_id], predicted_class_id\n\nidx = 0\ntotal = test_datasets[\"test\"][-100:]\n# print(total)\nsize = 100\n# test_set =  test_datasets[\"test\"].select(range(total-size, total))\n\nfor idx, val in enumerate(total[\"text\"]):\n    label, class_id = get_predict_label(val)\n    print(f'original>>\\t{total[\"text_label\"][idx]}\\t\\t<predicted>>>>\\t{label}\\t{class_id}')","metadata":{"_uuid":"fc31f0e8-a808-4867-bac3-781bfd49cff9","_cell_guid":"41b2a9ef-ac94-4c88-80cd-9a5f92277be3","collapsed":false,"execution":{"iopub.status.busy":"2023-02-23T18:28:42.193958Z","iopub.execute_input":"2023-02-23T18:28:42.194333Z","iopub.status.idle":"2023-02-23T18:28:42.208892Z","shell.execute_reply.started":"2023-02-23T18:28:42.194301Z","shell.execute_reply":"2023-02-23T18:28:42.207933Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}